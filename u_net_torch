#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Mon Mar 22 11:53:30 2021

@author: maya.fi@bm.technion.ac.il
"""
 width = params['new_w']
    height = params['new_h']
    inputs = Input(shape=(height,width,params['multi_slice_n'])) 
   
    ## Stage 1 ##
    C1_1        = Conv2D(64, kernel_size=3, strides=1, padding='same')(inputs)
import torch.nn.functional as F

class Net(nn.Module):
    def __init__(self, params):
        super(Net, self).__init__()
        self.batch_size = params['batch_size']
        self.kernel_size = params['ker_size']
        multi_slice_n = params['multi_slice_n']
        self.h = paramss['new_h']
        self.w = params['new_w']
        enc_d = params['encoder_depth']
        cen_d = params['center_depth'] 
        dec_d = params['decoder_depth'] 
        #encoder
        self.enc_conv1 = nn.Conv2d(multi_slice_n, enc_d[0], kernel_size=self.kernel_size)
        self.enc_conv2 = nn.Conv2d(enc_d[0], enc_d[1], kernel_size=self.kernel_size)
        self.enc_conv3 = nn.Conv2d(enc_d[1], enc_d[2], kernel_size=self.kernel_size)
        self.cen_conv0 = nn.Conv2d(enc_d[2], cen_d[0], kernel_size=self.kernel_size)
        self.dec_conv1 = nn.Conv2d(cen_d[0], dec_d[0], kernel_size=self.kernel_size)
        self.dec_conv2 = nn.Conv2d(dec_d[0], dec_d[1], kernel_size=self.kernel_size, strides=1, bias=True)
        self.dec_conv3 = nn.Conv2d(dec_d[1], dec_d[2], kernel_size=self.kernel_size)
        self.fin_conv0 = nn.Conv2d(dec_d[2], 1, kernel_size=1, strides=1, bias=True)

        self.pool = nn.MaxPool2d(2, 2)
        self.conv2 = nn.Conv2d(6, 16, 5)
        self.fc1 = nn.Linear(16 * 5 * 5, 120)
        self.fc2 = nn.Linear(120, 84)
        self.fc3 = nn.Linear(84, 10)

    def forward(self, x):
        x = self.pool(F.relu(self.conv1(x)))
        x = self.pool(F.relu(self.conv2(x)))
        x = x.view(-1, 16 * 5 * 5)
        x = F.relu(self.fc1(x))
        x = F.relu(self.fc2(x))
        x = self.fc3(x)
        return x


net = Net()